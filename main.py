__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
import streamlit as st
import vercel_ai
import json
import chromadb
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.vectorstores import Chroma
from load_resume import main
from config import models, openai_api
import openai
from langchain.llms import OpenAI
openai.api_key = openai_api

main()

def generate_answer(prompt):
    answer = ""
    try:
        client = vercel_ai.Client()
        for chunk in client.generate('openai:gpt-3.5-turbo', prompt): answer += chunk

    except:
        response = openai.Completion.create(model="text-davinci-003",
            prompt=prompt,
            temperature=0,
            max_tokens=500,
            top_p=1.0,
            frequency_penalty=0.0,
            presence_penalty=0.0)
        
        answer = response['choices'][0]['text'].strip()
        


    
    return answer


embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
persist_directory = 'chroma_db'


vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)

retriever = vectordb.as_retriever()

with st.sidebar:
    st.title('ðŸ¦œï¸ðŸ”—RESUME-CHAT \n PDF Q/A Retrieval LLM-LANGCHAIN AGENTðŸ¤—')
    st.markdown('''
    ## About APP:
    The application can be used to chat with my resume and recieve answers to your queries.\n
    Chromadb is used for storing the vector embeddings which were created using sentence transformer's all-MiniLM-L6-v2.\n
    We use sentence similarity to return the most matching document from the corpus and provide it as context to the LLM.\n
                         
    The app's primary resource is utilised to create::

    - [streamlit](https://streamlit.io/)
    - [Langchain](https://docs.langchain.com/docs/)
    - [Vercel Playground](https://sdk.vercel.ai/)
    - [Chroma DB](https://www.trychroma.com/)
    - [Sentence Transformer](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

    A big thanks to [ADING](https://github.com/ading2210) whose module [vercel-llm-api](https://pypi.org/project/vercel-llm-api/) makes all of this possible.

    ## About me:

    - [Linkedin](https://www.linkedin.com/in/akshaynambiar7/)
    - [Website](https://akshaypn.github.io/)
    
    ''')
    st.write('ðŸ’¡All about resume-chat, created by [Akshay](https://www.linkedin.com/in/akshaynambiar7/)ðŸ¤—')
    st.info("The agent may output incorrect, ambiguous and disrespectful answers. The Author does not endorse the facts/statements generated by the models.")



st.title("RESUME CHAT (Q/A)")
st.header("Ask any question !!")
st.info("Write your question, choose the model (gpt-3.5 works best) and hit Answer. The results will be based on my resume")
query = st.text_area("Enter your question here", "Why is Akshay the ideal candidate for the Senior Machine Learning Engineer(NLP) role?\n\n\
Write your answer with 4-5 short and sharp bullet points")


try:
    matching_docs = vectordb.similarity_search(query)

    prompt = f"""You are the helpful, polite and noble assistant of Akshay P Nambiar. Always remember the following things while answering: 
    1. Be precise, concise and helpful.
    2. Answer in a well structured professional manner
    3. Provide well formatted and structured replies.
    4. If the question is derogatory, abusive or contains profanity, refuse to answer.

    Given the excerpt from the resume of Akshay P Nambiar as context, answer the following question. 
    ### Question:
    {query}

    ### Context :
    {matching_docs[0]}
    """
except:
    prompt = f"""You are the helpful, polite and noble assistant of Akshay P Nambiar. Always remember the following things: 
    1. Try to be precise and concise. Finish the answer in less than 200 words.
    2. Answer in a well structured professional manner.
    3. If the input is derogatory, abusive or contains profanity, refuse to answer.

    

    ### Context :
    The question is beyond the scope of this resume. Reply that you need more information. 
    """

answer = ""
if st.button('Answer'):
    try:
        with st.spinner("Shifting Rocks.. Checking nooks and corners... Thinking hard... ðŸ¤”"):
            answer = generate_answer(prompt)
            
            st.success("Answer Generated âœ…")
            if len(answer) > 1:
                st.write(answer)  
            else:
                st.write("Problem with API")
                st.exception("API timed out. Please try after a minute or choose another model.")
    except Exception as e:
        st.write(e)
        st.exception("API timed out. Please try after a minute or choose another model.")